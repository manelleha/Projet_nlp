# ğŸ§  Projet NLP â€” Sentiment Analysis with Transfer Learning & Few-Shot

## ğŸ“Œ Objectif du projet
Ce projet vise Ã  analyser des tweets liÃ©s Ã  des entitÃ©s et prÃ©dire leur sentiment parmi 4 classes :
0 Negative, 1 Neutral, 2 Positive, 3 Irrelevant.

Le projet explore :
- le transfert learning
- le fine-tuning
- le few-shot learning (prompting LLM)
- lâ€™impact de la quantitÃ© de donnÃ©es

## ğŸ—‚ï¸ Structure
Projet_nlp/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ twitter_train_clean.csv   # dataset d'entraÃ®nement nettoyÃ©
â”‚   â””â”€â”€ twitter_val_clean.csv     # dataset de validation nettoyÃ©
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ eda.py                    # exploration des donnÃ©es
â”‚   â”œâ”€â”€ tl_baseline_frozen.py     # baseline TL (BERT gelÃ© + LogisticRegression)
â”‚   â”œâ”€â”€ tl_finetune.py            # fine-tuning BERT
â”‚   â”œâ”€â”€ fewshot_prompting_groq.py # vrai few-shot (prompting LLM)
â”‚   â””â”€â”€ plot_results.py           # (Ã  complÃ©ter) visualisations & learning curves
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ bert_finetuned/           # modÃ¨le fine-tunÃ© sauvegardÃ©
â”‚
â””â”€â”€ reports/
    â”œâ”€â”€ tl_baseline_frozen.csv
    â”œâ”€â”€ finetune_metrics.csv
    â”œâ”€â”€ finetune_classification_report.txt
    â”œâ”€â”€ fewshot_prompting_groq_results.csv
    â””â”€â”€ figures/


## ğŸ§ª Scripts principaux
- eda.py : exploration des donnÃ©es
- tl_baseline_frozen.py : baseline TL gelÃ©e
- tl_finetune.py : fine-tuning BERT
- fewshot_prompting_groq.py : few-shot par prompting
- plot_results.py : visualisations finales


## ğŸ§© RÃ´le des fichiers principaux du projet
# ğŸ“Š eda.py â€” Exploration des donnÃ©es
RÃ´le : comprendre le dataset avant de modÃ©liser.
Ce script analyse :
la taille du dataset
la distribution des labels
la longueur des tweets
des exemples de textes par classe
des visualisations enregistrÃ©es dans reports/
Pourquoi câ€™est important :
Il permet de justifier les choix du modÃ¨le et dâ€™anticiper les difficultÃ©s (ex : classe Irrelevant plus complexe).
# ğŸ§± tl_baseline_frozen.py â€” Baseline de Transfert Learning (modÃ¨le gelÃ©)
RÃ´le : Ã©tablir une rÃ©fÃ©rence solide avec du transfert learning sans fine-tuning.
MÃ©thode :
BERT prÃ©-entraÃ®nÃ©
poids complÃ¨tement gelÃ©s
extraction dâ€™embeddings
classifieur simple (Logistic Regression)
Pourquoi :
Câ€™est la baseline principale demandÃ©e.
Elle permet de mesurer ce que vaut un modÃ¨le prÃ©-entraÃ®nÃ© sans adaptation au dataset.
# ğŸ§  tl_finetune.py â€” Fine-tuning de BERT
RÃ´le : amÃ©liorer la performance en adaptant le modÃ¨le au dataset.
MÃ©thode :
mÃªme modÃ¨le BERT
mais toutes les couches sont entraÃ®nÃ©es
apprentissage supervisÃ© sur les tweets
Pourquoi :
Permet de comparer :
modÃ¨le gelÃ© vs modÃ¨le adaptÃ©
et de dÃ©montrer concrÃ¨tement lâ€™intÃ©rÃªt du fine-tuning.
# ğŸ¯ fewshot_prompting_groq.py â€” Few-shot â€œcomme en coursâ€ (prompting)
RÃ´le : implÃ©menter le vrai few-shot vu en cours (TD Prompt Engineering).
MÃ©thode :
aucun entraÃ®nement
quelques exemples (K-shot) injectÃ©s dans le prompt
le LLM prÃ©dit directement le label
Pourquoi :
Ce fichier montre la capacitÃ© dâ€™un grand modÃ¨le Ã  apprendre uniquement par le contexte,
et permet de comparer :
apprentissage classique vs prompting sans entraÃ®nement.



##  Ã€ faire
- tester tl_finetune.py et fewshot_prompting_groq.py
- comparer les modeles -> faire une doc


