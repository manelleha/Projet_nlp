
### Structure des fichiers nettoyÃ©s :

| Colonne      | Type   | Description |
|--------------|---------|-------------|
| `clean_text` | string | Tweet nettoyÃ© (minuscule, sans URL, sans mentions, sans hashtags, sans symboles) |
| `label`      | int    | Classe de sentiment encodÃ©e (0â€“3) |

---

## ğŸ§¼ 2. Nettoyage effectuÃ©

Les transformations appliquÃ©es :

- Mise en minuscules  
- Suppression :
  - URLs (`http...`)
  - mentions (`@username`)
  - hashtags (`#topic`)
  - ponctuation et caractÃ¨res spÃ©ciaux  
- RÃ©duction des espaces multiples  
- Filtrage des tweets trop courts  
- Conversion du sentiment textuel en label numÃ©rique  

> âš ï¸ Le nettoyage permet aux modÃ¨les classiques (TF-IDF, logistic regression) et aux modÃ¨les Transformers de fonctionner correctement.

---

## ğŸ·ï¸ 3. Signification des labels

| Label | Nom original | Description |
|-------|---------------|-------------|
| **0** | Negative      | Opinion nÃ©gative envers lâ€™entitÃ© |
| **1** | Neutral       | Information factuelle, sans opinion |
| **2** | Positive      | Opinion favorable |
| **3** | Irrelevant    | Le tweet ne concerne pas rÃ©ellement l'entitÃ© |

---

## ğŸ“Š 4. Taille et distribution des classes

### **EntraÃ®nement (`twitter_train_clean.csv`)**
- **72 051 tweets**
- Distribution :

| Classe | Nombre |
|--------|---------|
| 0 (Negative) | 21 804 |
| 1 (Neutral)  | 17 623 |
| 2 (Positive) | 20 017 |
| 3 (Irrelevant) | 12 607 |

---

### **Validation (`twitter_val_clean.csv`)**
- **994 tweets**
- Distribution proche de celle du train :

| Classe | Nombre |
|--------|---------|
| 1 (Neutral)  | 285 |
| 2 (Positive) | 274 |
| 0 (Negative) | 263 |
| 3 (Irrelevant) | 172 |

> âœ”ï¸ Le jeu de validation est bien Ã©quilibrÃ© et reprÃ©sentatif â†’ parfait pour lâ€™Ã©valuation.

---

## ğŸ” 5. Pourquoi deux fichiers sÃ©parÃ©s ?

Nous utilisons :
- **un dataset d'entraÃ®nement** â†’ pour lâ€™apprentissage, y compris few-shot  
- **un dataset de validation** â†’ pour lâ€™Ã©valuation uniquement  

Cela garantit une comparaison stable et reproductible entre les modÃ¨les :
- baseline transfert learning  
- fine-tuning  
- few-shot learning (10 %, 20 %, 50 %, 100 % du train)

---

## âš™ï¸ 6. Exemple d'utilisation

### Charger les donnÃ©es :

```python
import pandas as pd

train = pd.read_csv("data/twitter_train_clean.csv")
val = pd.read_csv("data/twitter_val_clean.csv")
